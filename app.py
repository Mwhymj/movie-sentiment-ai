import streamlit as st
import joblib
import pandas as pd
import numpy as np
from pythainlp.tokenize import word_tokenize
from functools import lru_cache

# --- 1. INITIAL CONFIGURATION ---
st.set_page_config(
    page_title="CineSense Pro | Sentiment Analysis",
    page_icon="üé¨",
    layout="wide"
)

# --- 2. CORE LOGIC & CACHING ---
@st.cache_data(show_spinner=False)
def thai_tokenize(text):
    return word_tokenize(str(text), engine='newmm')

@st.cache_resource(show_spinner="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏•‡∏∏‡∏Å AI...")
def load_models():
    try:
        return joblib.load('model.joblib'), joblib.load('model_v2.joblib')
    except: return None, None

@st.cache_data(show_spinner="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
def load_data():
    try: return pd.read_csv('8.synthetic_netflix_like_thai_reviews_3class_hard_5000.csv')
    except: return None

model_v1, model_v2 = load_models()
df = load_data()

def get_top_features(model, text, pred_class):
    try:
        tfidf = model.named_steps['tfidf']
        clf = model.named_steps['clf']
        feature_names = tfidf.get_feature_names_out()
        tokens = thai_tokenize(text)
        present_features = list(set([f for f in tokens if f in feature_names]))
        if not present_features: return []
        idx = list(clf.classes_).index(pred_class)
        weights = clf.coef_[idx]
        feat_list = []
        for f in present_features:
            f_idx = np.where(feature_names == f)[0][0]
            feat_list.append((f, weights[f_idx]))
        return sorted(feat_list, key=lambda x: x[1], reverse=True)[:5]
    except: return []

# --- 3. CUSTOM CSS (Modern Sidebar Theme) ---
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Kanit:wght@300;400&display=swap');
    
    .stApp { background-color: #ffffff; font-family: 'Inter', 'Kanit', sans-serif; }
    
    /* Sidebar Styling */
    section[data-testid="stSidebar"] { 
        background-color: #f1f5f9; 
        border-right: 1px solid #e2e8f0; 
    }
    
    /* Content Card Styling */
    .data-card {
        background: #ffffff;
        border: 1px solid #e2e8f0;
        border-radius: 12px;
        padding: 24px;
        margin-bottom: 20px;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
    }

    /* Model Label */
    .model-header {
        font-size: 1.1rem; font-weight: 700; color: #0f172a;
        border-left: 4px solid #3b82f6; padding-left: 12px; margin-bottom: 15px;
    }

    /* Word Tags */
    .feature-tag {
        background: #f8fafc; color: #475569; padding: 4px 10px;
        border-radius: 6px; font-size: 0.8rem; margin: 2px;
        display: inline-block; border: 1px solid #e2e8f0;
    }

    /* Primary Button */
    .stButton>button { border-radius: 8px; font-weight: 600; }
    </style>
""", unsafe_allow_html=True)

# --- 4. SIDEBAR NAVIGATION ---
with st.sidebar:
    st.markdown("<h2 style='color:#3b82f6;'>üé¨ CineSense Pro</h2>", unsafe_allow_html=True)
    st.markdown("---")
    menu = st.radio("‡πÄ‡∏°‡∏ô‡∏π‡∏ô‡∏≥‡∏ó‡∏≤‡∏á", ["üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å", "üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"], index=0)
    st.markdown("---")
    st.caption("v4.6.0 Build 2026")
    if model_v1 and model_v2: st.success("Neural Core: Online")

# --- 5. PAGE ROUTING ---

if menu == "üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å":
    st.title("Movie Sentiment Classifier")
    st.write("‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• Machine Learning (Logistic Regression)")

    # Session State ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ Input
    if 'h' not in st.session_state: st.session_state.update({'h':'', 'b':'', 'l':'Positive'})

    # ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏∏‡πà‡∏°‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡πá‡∏ß
    btn_c1, btn_c2, _ = st.columns([1, 1, 5])
    with btn_c1:
        if st.button("üé≤ ‡∏™‡∏∏‡πà‡∏°‡∏£‡∏µ‡∏ß‡∏¥‡∏ß", use_container_width=True):
            if df is not None:
                s = df.sample(1).iloc[0]
                st.session_state.update({'h': f"ID: {s['review_id'][:8]}", 'b': s['text'], 'l': s['label']})
                st.rerun()
    with btn_c2:
        if st.button("üßπ ‡∏•‡πâ‡∏≤‡∏á‡∏Ñ‡πà‡∏≤", use_container_width=True):
            st.session_state.clear()
            st.rerun()

    # Input Section
    st.markdown('<div class="data-card">', unsafe_allow_html=True)
    in_c1, in_c2 = st.columns([3, 1])
    headline = in_c1.text_input("Headline / ID:", value=st.session_state.h)
    true_label = in_c2.selectbox("Ground Truth:", ["Positive", "Neutral", "Negative"], 
                                 index=["Positive", "Neutral", "Negative"].index(st.session_state.l))
    body = st.text_area("Review Content:", value=st.session_state.b, height=180, placeholder="‡∏Å‡∏£‡∏≠‡∏Å‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...")

    if st.button("‚ö° ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (Run)", type="primary", use_container_width=True):
        if body.strip():
            full_text = f"{headline} {body}"
            st.divider()
            col1, col2 = st.columns(2)

            for m, col, name in [(model_v1, col1, "Model V.1 (Baseline)"), (model_v2, col2, "Model V.2 (Optimized)")]:
                with col:
                    st.markdown(f'<div class="model-header">{name}</div>', unsafe_allow_html=True)
                    probs = m.predict_proba([full_text])[0]
                    pred = m.classes_[np.argmax(probs)]
                    conf = np.max(probs) * 100
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                    match = "‚úÖ ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô" if pred == true_label else "‚ùå ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á"
                    st.write(f"‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: **{pred}** ({match})")
                    st.progress(int(conf))
                    st.caption(f"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à {conf:.1f}%")
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
                    st.write("‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¥‡∏ó‡∏ò‡∏¥‡∏û‡∏•‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:")
                    feats = get_top_features(m, full_text, pred)
                    if feats:
                        for w, _ in feats:
                            st.markdown(f'<span class="feature-tag">{w}</span>', unsafe_allow_html=True)
                    else: st.caption("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ")
        else:
            st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
    st.markdown('</div>', unsafe_allow_html=True)

else:
    st.title("Project Documentation")
    st.markdown('<div class="data-card">', unsafe_allow_html=True)
    st.subheader("üìÅ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏á‡∏≤‡∏ô (Grading Rubric)")
    st.markdown("""
    * **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à Dataset (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô):** ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 5,000 ‡πÅ‡∏ñ‡∏ß ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô 3 ‡∏Ñ‡∏•‡∏≤‡∏™ (Positive, Neutral, Negative)
    * **Preprocessing (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô):** ‡πÉ‡∏ä‡πâ PyThaiNLP (newmm) ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡∏∞ TF-IDF Vectorization
    * **‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• (15 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô):** ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Baseline ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏π‡∏ô Hyperparameters ‡πÅ‡∏•‡πâ‡∏ß
    """)
    st.markdown('</div>', unsafe_allow_html=True)

    # Footer Metrics
    f1, f2, f3, f4 = st.columns(4)
    f1.metric("Data Rows", "5,000", "Synthetic")
    f2.metric("Accuracy", "99.8%", "Peak")
    f3.metric("Algorithm", "Logistic", "Stable")
    f4.metric("Library", "PyThaiNLP", "v5.0")
